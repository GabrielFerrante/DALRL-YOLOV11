{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85254ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78033e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações iniciais\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_clusters = 80  # Número de classes do COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b696892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações do COCO\n",
    "img_dir = os.path.join(\"F:/COCO-Dataset/\", \"train2017/train2017/\")\n",
    "ann_file = os.path.join(\"F:/COCO-Dataset/\", \"annotations2017/annotations2017/instances_train2017.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e7600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastas de saída\n",
    "output_dirs = {\n",
    "    \"raizes\": {\n",
    "        \"images\": \"F:/COCO-Dataset/train2017/clustering/train/images\",\n",
    "        \"labels\": \"F:/COCO-Dataset/train2017/clustering/train/labels\"\n",
    "    },\n",
    "    \"fronteiras\": {\n",
    "        \"images\": \"F:/COCO-Dataset/train2017/clustering/train/images\",\n",
    "        \"labels\": \"F:/COCO-Dataset/train2017/clustering/train/labels\"\n",
    "    },\n",
    "    \"restante\": {\n",
    "        \"images\": \"F:/COCO-Dataset/train2017/clustering/pool/images\",\n",
    "        \"labels\": \"F:/COCO-Dataset/train2017/clustering/pool/labels\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71cdc2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=11.53s)\n",
      "creating index...\n",
      "index created!\n",
      "Total de imagens: 118287\n",
      "Total de categorias: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\MODERN\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Anaconda\\envs\\MODERN\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Criar estrutura de diretórios\n",
    "for group in output_dirs.values():\n",
    "    os.makedirs(group[\"images\"], exist_ok=True)\n",
    "    os.makedirs(group[\"labels\"], exist_ok=True)\n",
    "\n",
    "# 1. Carregar dataset COCO\n",
    "coco = COCO(ann_file)\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "# Mapeamento de IDs COCO para YOLO\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "categories.sort(key=lambda x: x['id'])\n",
    "coco_id_to_yolo_id = {cat['id']: idx for idx, cat in enumerate(categories)}\n",
    "\n",
    "print(f\"Total de imagens: {len(img_ids)}\")\n",
    "print(f\"Total de categorias: {len(categories)}\")\n",
    "\n",
    "# 2. Carregar modelo ResNet-18\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-1])  # Remove a última camada\n",
    "model.to(device).eval()\n",
    "\n",
    "# Transformações das imagens\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9f6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Função para extrair embeddings\n",
    "def extract_embeddings(img_paths):\n",
    "    embeddings = []\n",
    "    valid_indices = []\n",
    "    model.to(device)\n",
    "    for idx, path in enumerate(tqdm(img_paths, desc=\"Extraindo embeddings\")):\n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features = model(img_tensor)\n",
    "            \n",
    "            embeddings.append(features.squeeze().cpu().numpy().flatten())\n",
    "            valid_indices.append(idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {path}: {str(e)}\")\n",
    "    \n",
    "    return np.array(embeddings), valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f7265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagens válidas: 118287/118287\n"
     ]
    }
   ],
   "source": [
    "# 4. Obter caminhos das imagens\n",
    "img_paths = []\n",
    "valid_img_ids = []\n",
    "\n",
    "for img_id in img_ids:\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    img_path = os.path.join(img_dir, img_info[\"file_name\"])\n",
    "    if os.path.exists(img_path):\n",
    "        img_paths.append(img_path)\n",
    "        valid_img_ids.append(img_id)\n",
    "\n",
    "print(f\"Imagens válidas: {len(img_paths)}/{len(img_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135657b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraindo embeddings: 100%|██████████| 118287/118287 [47:16<00:00, 41.71it/s] \n"
     ]
    }
   ],
   "source": [
    "# 5. Extrair embeddings (usando GPU)\n",
    "embeddings, valid_indices = extract_embeddings(img_paths)\n",
    "valid_img_ids = [valid_img_ids[i] for i in valid_indices]\n",
    "img_paths = [img_paths[i] for i in valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3277828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Clusterização com K-Means\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec3ed56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Identificar raízes e fronteiras\n",
    "raizes = {}\n",
    "fronteiras = {i: [] for i in range(num_clusters)}\n",
    "resto = []\n",
    "\n",
    "for cluster_id in range(num_clusters):\n",
    "    # Índices das imagens deste cluster\n",
    "    indices = np.where(clusters == cluster_id)[0]\n",
    "    \n",
    "    if len(indices) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calcular distâncias para o centróide\n",
    "    cluster_embeddings = embeddings[indices]\n",
    "    distancias = np.linalg.norm(cluster_embeddings - centroids[cluster_id], axis=1)\n",
    "    \n",
    "    # 7.1 Encontrar raiz (ponto mais próximo do centróide)\n",
    "    raiz_idx = indices[np.argmin(distancias)]\n",
    "    raizes[cluster_id] = raiz_idx\n",
    "    \n",
    "    # 7.2 Calcular distâncias para outros centróides\n",
    "    outras_distancias = []\n",
    "    for other_id in range(num_clusters):\n",
    "        if other_id != cluster_id:\n",
    "            dist = np.linalg.norm(cluster_embeddings - centroids[other_id], axis=1)\n",
    "            outras_distancias.append(dist)\n",
    "    \n",
    "    # 7.3 Encontrar pontos de fronteira (mais próximos de outros clusters)\n",
    "    min_outras_distancias = np.min(outras_distancias, axis=0)\n",
    "    razoes = distancias / min_outras_distancias\n",
    "    \n",
    "    # Selecionar 20% com maiores razões (mais próximos da fronteira)\n",
    "    n_fronteira = max(1, int(0.2 * len(indices)))\n",
    "    fronteira_indices = razoes.argsort()[-n_fronteira:]\n",
    "    \n",
    "    # 7.4 Classificar imagens\n",
    "    for i, idx in enumerate(indices):\n",
    "        if idx == raiz_idx:\n",
    "            continue  # Raiz já foi registrada\n",
    "        elif i in fronteira_indices:\n",
    "            fronteiras[cluster_id].append(idx)\n",
    "        else:\n",
    "            resto.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c067093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Função para processar grupos de imagens\n",
    "def process_group(img_indices, group_name):\n",
    "    image_dir = output_dirs[group_name][\"images\"]\n",
    "    label_dir = output_dirs[group_name][\"labels\"]\n",
    "    \n",
    "    for idx in tqdm(img_indices, desc=f\"Processando {group_name}\"):\n",
    "        img_id = valid_img_ids[idx]\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        img_file = img_info[\"file_name\"]\n",
    "        img_path = os.path.join(img_dir, img_file)\n",
    "        \n",
    "        # Copiar imagem\n",
    "        shutil.copy(img_path, os.path.join(image_dir, img_file))\n",
    "        \n",
    "        # Gerar rótulo YOLO\n",
    "        label_file = img_file.replace(\".jpg\", \".txt\")\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        \n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        annotations = coco.loadAnns(ann_ids)\n",
    "        \n",
    "        with open(label_path, \"w\") as f:\n",
    "            for ann in annotations:\n",
    "                if \"bbox\" not in ann or ann[\"area\"] <= 0:\n",
    "                    continue\n",
    "                \n",
    "                # Converter ID COCO para YOLO\n",
    "                yolo_class_id = coco_id_to_yolo_id.get(ann['category_id'], -1)\n",
    "                if yolo_class_id == -1:\n",
    "                    continue\n",
    "                \n",
    "                # Converter bbox\n",
    "                x, y, w, h = ann[\"bbox\"]\n",
    "                img_width = img_info[\"width\"]\n",
    "                img_height = img_info[\"height\"]\n",
    "                \n",
    "                # Normalizar coordenadas\n",
    "                x_center = (x + w / 2) / img_width\n",
    "                y_center = (y + h / 2) / img_height\n",
    "                w_norm = w / img_width\n",
    "                h_norm = h / img_height\n",
    "                \n",
    "                # Escrever no formato YOLO\n",
    "                f.write(f\"{yolo_class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97d069c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando raizes: 100%|██████████| 80/80 [00:01<00:00, 68.87it/s]\n",
      "Processando fronteiras: 100%|██████████| 23624/23624 [08:40<00:00, 45.36it/s] \n",
      "Processando restante: 100%|██████████| 94583/94583 [38:55<00:00, 40.50it/s]  \n"
     ]
    }
   ],
   "source": [
    "# 9. Processar cada grupo\n",
    "# Raízes (uma por cluster)\n",
    "process_group(raizes.values(), \"raizes\")\n",
    "\n",
    "# Fronteiras (todos os clusters juntos)\n",
    "all_fronteiras = [idx for indices in fronteiras.values() for idx in indices]\n",
    "process_group(all_fronteiras, \"fronteiras\")\n",
    "\n",
    "# Restante\n",
    "process_group(resto, \"restante\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MODERN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
