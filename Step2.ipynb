{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84423812",
   "metadata": {},
   "source": [
    "# Etapa 2\n",
    "- Calculo da Entropia e métricas.\n",
    "- Criação do agente de reforço para seleção da próxima rotulação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d09e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50edd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c798e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_in_pool = [f\"E:/COCO-Dataset/train2017/val/images/{f}\" for f in os.listdir(\"E:/COCO-Dataset/train2017/val/images/\")]\n",
    "oracle_labels = {img: img.replace(\".jpg\",\".txt\").replace(\"images\",\"labels\") for img in images_in_pool}  # Preencher com anotações reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038b3694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/COCO-Dataset/train2017/val/images/000000000009.jpg\n",
      "E:/COCO-Dataset/train2017/val/labels/000000000009.txt\n"
     ]
    }
   ],
   "source": [
    "print(images_in_pool[0])\n",
    "print(oracle_labels[images_in_pool[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0545e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python313\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "  # 1. Carregar YOLOv11\n",
    "yolo = YOLO(\"runs/detect/yolov11-initial/weights/best.pt\").to(DEVICE)\n",
    "    \n",
    "from envRL import YOLORLEnv\n",
    "# 3. Criar ambiente\n",
    "env = YOLORLEnv(\n",
    "        yolo_model=yolo,\n",
    "        unlabeled_images=images_in_pool,\n",
    "        oracle_labels=oracle_labels,\n",
    "        batch_size=8,\n",
    ")\n",
    "\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Hyperparâmetros ajustados\n",
    "policy_kwargs = {\n",
    "    'net_arch': {\n",
    "        'pi': [256, 256],  # Rede de política\n",
    "        'vf': [256, 256]   # Rede de valor\n",
    "    },\n",
    "    'optimizer_class': torch.optim.AdamW,\n",
    "    'activation_fn': torch.nn.ReLU,\n",
    "    'ortho_init': True\n",
    "}\n",
    "\n",
    "agent = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    n_steps=2048,              # Tamanho do rollout\n",
    "    batch_size=8,              # Tamanho do mini-batch\n",
    "    gamma=0.99,                # Fator de desconto\n",
    "    gae_lambda=0.95,           # Parâmetro GAE\n",
    "    ent_coef=0.01,             # Coeficiente de entropia\n",
    "    learning_rate=3e-4,        # Taxa de aprendizado\n",
    "    clip_range=0.2,            # Clipping de política\n",
    "    verbose=2,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    device=\"cuda\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cccfd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confs: [    0.50048     0.49952]\n",
      "ENTROPIA 0.6931467056274414\n",
      "Confs: [    0.50048     0.49952]\n",
      "ENTROPIA 0.6931467056274414\n",
      "Movidos: 000000218716.jpg e label para treinamento\n",
      "Confs: [          1]\n",
      "ENTROPIA -0.0\n",
      "Confs: [    0.53608     0.25315     0.21077]\n",
      "ENTROPIA 1.0101687908172607\n",
      "Confs: []\n",
      "Confs: []\n",
      "Movidos: 000000432843.jpg e label para treinamento\n",
      "Confs: [          1]\n",
      "ENTROPIA -0.0\n",
      "Confs: [    0.56892     0.43108]\n",
      "ENTROPIA 0.6836172342300415\n",
      "Confs: [    0.25139     0.23703     0.19626     0.15321    0.088625    0.073481]\n",
      "ENTROPIA 1.7019240856170654\n",
      "Confs: [          1]\n",
      "ENTROPIA -0.0\n",
      "Confs: [    0.25679     0.22627     0.22002     0.13183    0.089244    0.075856]\n",
      "ENTROPIA 1.6968560218811035\n",
      "Confs: [    0.25679     0.22627     0.22002     0.13183    0.089244    0.075856]\n",
      "ENTROPIA 1.6968560218811035\n",
      "Movidos: 000000362547.jpg e label para treinamento\n",
      "Confs: [    0.12155     0.10794    0.098344    0.082388    0.079591     0.07284    0.069629    0.059602    0.055142    0.053471    0.048296    0.042318    0.038434    0.037266    0.033185]\n",
      "ENTROPIA 2.6334972381591797\n",
      "Confs: [    0.12155     0.10794    0.098344    0.082388    0.079591     0.07284    0.069629    0.059602    0.055142    0.053471    0.048296    0.042318    0.038434    0.037266    0.033185]\n",
      "ENTROPIA 2.6334972381591797\n",
      "Movidos: 000000422040.jpg e label para treinamento\n",
      "Confs: [    0.32474     0.24827     0.18095     0.12483      0.1212]\n",
      "ENTROPIA 1.5360091924667358\n",
      "Confs: [    0.32543     0.29303     0.27357     0.10797]\n",
      "ENTROPIA 1.3199542760849\n",
      "Confs: [          1]\n",
      "ENTROPIA -0.0\n",
      "Confs: [          1]\n",
      "ENTROPIA -0.0\n",
      "Movidos: 000000083716.jpg e label para treinamento\n",
      "Confs: [          1]\n",
      "ENTROPIA -0.0\n",
      "Confs: [    0.27135     0.20678     0.15351     0.14202     0.11708     0.10926]\n",
      "ENTROPIA 1.737733244895935\n",
      "Confs: [    0.27135     0.20678     0.15351     0.14202     0.11708     0.10926]\n",
      "ENTROPIA 1.737733244895935\n",
      "Movidos: 000000549715.jpg e label para treinamento\n",
      "Confs: [    0.38817     0.34979     0.26204]\n",
      "ENTROPIA 1.0856977701187134\n",
      "Confs: [          1]\n",
      "ENTROPIA -0.0\n",
      "Confs: []\n",
      "Confs: []\n",
      "Movidos: 000000516602.jpg e label para treinamento\n",
      "Confs: [    0.59327     0.40673]\n",
      "ENTROPIA 0.6756463050842285\n",
      "Confs: [          1]\n",
      "ENTROPIA -0.0\n",
      "Confs: [     0.4066     0.30886     0.28454]\n",
      "ENTROPIA 1.0864129066467285\n",
      "Confs: [     0.4066     0.30886     0.28454]\n",
      "ENTROPIA 1.0864129066467285\n",
      "Movidos: 000000339588.jpg e label para treinamento\n",
      "Erro no re-treino: 'YOLORLEnv' object has no attribute 'total_epochs'\n",
      "Conteúdo do arquivo temporário:\n",
      "names:\n",
      "  0: person\n",
      "  1: bicycle\n",
      "  2: car\n",
      "  3: motorcycle\n",
      "  4: airplane\n",
      "  5: bus\n",
      "  6: train\n",
      "  7: truck\n",
      "  8: boat\n",
      "  9: traffic light\n",
      "  10: fire hydrant\n",
      "  11: stop sign\n",
      "  12: parking meter\n",
      "  13: bench\n",
      "  14: bird\n",
      "  15: cat\n",
      "  16: dog\n",
      "  17: horse\n",
      "  18: sheep\n",
      "  19: cow\n",
      "  20: elephant\n",
      "  21: bear\n",
      "  22: zebra\n",
      "  23: giraffe\n",
      "  24: backpack\n",
      "  25: umbrella\n",
      "  26: handbag\n",
      "  27: tie\n",
      "  28: suitcase\n",
      "  29: frisbee\n",
      "  30: skis\n",
      "  31: snowboard\n",
      "  32: sports ball\n",
      "  33: kite\n",
      "  34: baseball bat\n",
      "  35: baseball glove\n",
      "  36: skateboard\n",
      "  37: surfboard\n",
      "  38: tennis racket\n",
      "  39: bottle\n",
      "  40: wine glass\n",
      "  41: cup\n",
      "  42: fork\n",
      "  43: knife\n",
      "  44: spoon\n",
      "  45: bowl\n",
      "  46: banana\n",
      "  47: apple\n",
      "  48: sandwich\n",
      "  49: orange\n",
      "  50: broccoli\n",
      "  51: carrot\n",
      "  52: hot dog\n",
      "  53: pizza\n",
      "  54: donut\n",
      "  55: cake\n",
      "  56: chair\n",
      "  57: couch\n",
      "  58: potted plant\n",
      "  59: bed\n",
      "  60: dining table\n",
      "  61: toilet\n",
      "  62: tv\n",
      "  63: laptop\n",
      "  64: mouse\n",
      "  65: remote\n",
      "  66: keyboard\n",
      "  67: cell phone\n",
      "  68: microwave\n",
      "  69: oven\n",
      "  70: toaster\n",
      "  71: sink\n",
      "  72: refrigerator\n",
      "  73: book\n",
      "  74: clock\n",
      "  75: vase\n",
      "  76: scissors\n",
      "  77: teddy bear\n",
      "  78: hair drier\n",
      "  79: toothbrush\n",
      "nc: 80\n",
      "path: coco\n",
      "train: E:/COCO-Dataset/train2017/train/images/\n",
      "val: E:/COCO-Dataset/val2017/images/\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 22.48.7 MB/s, size: 144.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\COCO-Dataset\\val2017\\labels.cache... 5000 images, 48 backgrounds, 0 corrupt: 100%|██████████| 5000/5000 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  25%|██▍       | 77/313 [00:27<01:24,  2.78it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "agent.learn(\n",
    "    total_timesteps=5000,\n",
    ")\n",
    "# Salvar versão final\n",
    "agent.save(\"ppo_agent_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c424a1b",
   "metadata": {},
   "source": [
    "# Saída de treinamento do algoritmo PPO (Proximal Policy Optimization) no Stable Baselines3\n",
    "\n",
    "**n_updates** \n",
    "\n",
    "Número de atualizações dos parâmetros da política (rede neural) durante o treinamento.\n",
    "Cada \"update\" corresponde a uma época de treinamento em um mini-batch de dados coletados.\n",
    "\n",
    "**policy_gradient_loss**\n",
    "\n",
    "Perda associada à política (a função que decide ações).\n",
    "Mede quão bem a política está maximizando a vantagem esperada (recompensas futuras ajustadas pela linha de base).\n",
    "- Valores negativos indicam que a política está melhorando (a vantagem está aumentando).\n",
    "- Valores positivos podem indicar instabilidade ou dificuldade de convergência.\n",
    "\n",
    "**value_loss**\n",
    "\n",
    "Perda associada à função de valor (estimador do retorno esperado).\n",
    "Mede o erro na previsão do valor esperado (recompensa acumulada futura) para um estado.\n",
    "- Quanto menor, melhor a função de valor está estimando as recompensas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MODERN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
